{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import time as time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# 定义数据集类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "class Custom1DCNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, hidden_size):\n",
    "        super(Custom1DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=4)\n",
    "        self.fc1 = nn.Linear(out_channels * (2048 // 4-1), hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x   \n",
    "\n",
    "def Set_Random_State():\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    return\n",
    "    \n",
    "def Read_Data():\n",
    "    # 从Excel读取数据集\n",
    "    data_df = pd.read_excel('Pb1.xlsx', sheet_name='Sheet1',header=None)\n",
    "    data = data_df.iloc[0:, :2048].values\n",
    "    label_df = pd.read_excel('Pb1.xlsx',sheet_name='Sheet2',header=None)\n",
    "    labels = label_df.iloc[0:, 0].values\n",
    "    return data,label_df\n",
    "\n",
    "\n",
    "def Split_with_Sequential(data,labels,size):\n",
    "    # 按顺序划分数据集\n",
    "    split_index = int(len(data) * size)\n",
    "    data_train = data[:split_index]\n",
    "    labels_train = labels[:split_index]\n",
    "    data_test = data[split_index:]\n",
    "    labels_test = labels[split_index:]\n",
    "    return data_train,data_test,labels_train,labels_test\n",
    "\n",
    "def Split_with_Random(data,labels,size):\n",
    "    # 随机划分\n",
    "    data_train, data_test, labels_train, labels_test= train_test_split(data, labels, train_size=size, random_state=42) \n",
    "    return data_train, data_test, labels_train, labels_test\n",
    "\n",
    "def Standardlization(data):\n",
    "    # 数据预处理：标准化 + 整理为1DCNN需要的形式\n",
    "    scaler = StandardScaler()\n",
    "    data_normalized = scaler.fit_transform(data)\n",
    "    return data_normalized\n",
    "\n",
    "def Data_Augmentation(data):\n",
    "    data = np.expand_dims(data,axis=1)\n",
    "    return data\n",
    "\n",
    "def Data_to_Tensor(data_train, data_test, labels_train, labels_test):\n",
    "    data_train_tensor = torch.from_numpy(np.array(data_train, dtype=np.float32))\n",
    "    labels_train_tensor = torch.from_numpy(np.array(labels_train, dtype=np.float32))\n",
    "    data_test_tensor = torch.from_numpy(np.array(data_test, dtype=np.float32))\n",
    "    labels_test_tensor = torch.from_numpy(np.array(labels_test, dtype=np.float32))\n",
    "    \n",
    "    return data_train_tensor, labels_train_tensor, data_test_tensor, labels_test_tensor\n",
    "\n",
    "\n",
    "def Load_Data_For_NN(data_train,labels_train,batch_size):\n",
    "    # 准备数据\n",
    "    train_dataset = CustomDataset(data_train, labels_train)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_dataloader\n",
    "\n",
    "def one_dim_CNN_Initialization(in_channels,out_channels,kernel_size,hidden_size):    \n",
    "    model = Custom1DCNN(in_channels, out_channels, kernel_size, hidden_size)\n",
    "    return model\n",
    "\n",
    "def Super_Parameters(batch_size=None, learning_rate=None, num_epochs=None):\n",
    "    default_batch_size = 57\n",
    "    default_learning_rate = 0.001\n",
    "    default_num_epochs = 20\n",
    "    \n",
    "    if batch_size is None:\n",
    "        batch_size = default_batch_size\n",
    "    if learning_rate is None:\n",
    "        learning_rate = default_learning_rate\n",
    "    if num_epochs is None:\n",
    "        num_epochs = default_num_epochs\n",
    "        \n",
    "    return batch_size, learning_rate, num_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/0_qk2vws42gcfzt8nv_tksvr0000gn/T/ipykernel_17243/2153395517.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data = torch.tensor(data, dtype=torch.float32)\n",
      "/var/folders/81/0_qk2vws42gcfzt8nv_tksvr0000gn/T/ipykernel_17243/2153395517.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "Set_Random_State()\n",
    "data,labels = Read_Data()\n",
    "data_normalized = Standardlization(data)\n",
    "data= Data_Augmentation(data_normalized)\n",
    "data_train,data_test,labels_train,labels_test = Split_with_Sequential(data,labels,0.9)\n",
    "data_train_tensor, labels_train_tensor, data_test_tensor, labels_test_tensor = Data_to_Tensor(data_train,data_test,labels_train,labels_test)\n",
    "train_dataloader= Load_Data_For_NN(data_train_tensor,labels_train_tensor,57)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/110], Loss: 555.7669067382812, Train RMSE: 23.46881103515625, Train R^2: 0.99617436121542\n",
      "Test RMSE: 166.0845927783982\n",
      "Test R2: 0.32796261158783335\n",
      "Epoch [110/110], Loss: 563.30810546875, Train RMSE: 23.647274017333984, Train R^2: 0.9961159572531151\n",
      "Test RMSE: 190.49065617533805\n",
      "Test R2: 0.11593927111733748\n",
      "Epoch [110/110], Loss: 485.92242431640625, Train RMSE: 21.388824462890625, Train R^2: 0.9968224261855533\n",
      "Test RMSE: 171.0204406560807\n",
      "Test R2: 0.2874246649216279\n",
      "Epoch [110/110], Loss: 622.9754028320312, Train RMSE: 24.81196403503418, Train R^2: 0.995723936834722\n",
      "Test RMSE: 170.70406041218527\n",
      "Test R2: 0.2900586918956064\n",
      "Epoch [110/110], Loss: 327.2597961425781, Train RMSE: 17.284116744995117, Train R^2: 0.9979250088633662\n",
      "Test RMSE: 175.0460079947694\n",
      "Test R2: 0.25348392268427533\n",
      "Epoch [110/110], Loss: 570.8696899414062, Train RMSE: 23.69324493408203, Train R^2: 0.996100841440211\n",
      "Test RMSE: 175.32551496012823\n",
      "Test R2: 0.25109800102648394\n",
      "Epoch [110/110], Loss: 463.59271240234375, Train RMSE: 20.88506507873535, Train R^2: 0.9969703429040729\n",
      "Test RMSE: 171.86184669088254\n",
      "Test R2: 0.28039579644526036\n",
      "Epoch [110/110], Loss: 297.8969421386719, Train RMSE: 16.495512008666992, Train R^2: 0.9981100366712083\n",
      "Test RMSE: 170.1504249962004\n",
      "Test R2: 0.2946562541747707\n",
      "Epoch [110/110], Loss: 527.443115234375, Train RMSE: 22.385284423828125, Train R^2: 0.9965194569450085\n",
      "Test RMSE: 185.1709567642155\n",
      "Test R2: 0.16462690346607545\n",
      "Epoch [110/110], Loss: 800.4942016601562, Train RMSE: 28.099306106567383, Train R^2: 0.9945158041107244\n",
      "Test RMSE: 157.8435694261702\n",
      "Test R2: 0.3930002248651112\n",
      "Epoch [110/110], Loss: 525.5759887695312, Train RMSE: 22.728557586669922, Train R^2: 0.9964118915991327\n",
      "Test RMSE: 186.52295511533373\n",
      "Test R2: 0.1523836637425534\n",
      "Epoch [110/110], Loss: 633.3662109375, Train RMSE: 24.918500900268555, Train R^2: 0.9956871376662952\n",
      "Test RMSE: 181.82663139360164\n",
      "Test R2: 0.1945293331027793\n",
      "Epoch [110/110], Loss: 451.3421325683594, Train RMSE: 20.69972038269043, Train R^2: 0.9970238774883846\n",
      "Test RMSE: 171.81712861971224\n",
      "Test R2: 0.28077022656009676\n",
      "Epoch [110/110], Loss: 683.8300170898438, Train RMSE: 25.562211990356445, Train R^2: 0.9954614342162476\n",
      "Test RMSE: 155.70034906130402\n",
      "Test R2: 0.40937215762651513\n",
      "Epoch [110/110], Loss: 274.4633483886719, Train RMSE: 15.89157772064209, Train R^2: 0.9982458940104849\n",
      "Test RMSE: 195.70654493058595\n",
      "Test R2: 0.06686292896561985\n",
      "Epoch [110/110], Loss: 542.2916259765625, Train RMSE: 22.95216178894043, Train R^2: 0.9963409442797542\n",
      "Test RMSE: 162.2426914938984\n",
      "Test R2: 0.35869440603163383\n",
      "Epoch [110/110], Loss: 572.1519775390625, Train RMSE: 23.686128616333008, Train R^2: 0.9961031835538027\n",
      "Test RMSE: 161.856568632639\n",
      "Test R2: 0.3617432717621726\n",
      "Epoch [110/110], Loss: 2689.003662109375, Train RMSE: 49.168357849121094, Train R^2: 0.9832083556922454\n",
      "Test RMSE: 140.70774503752008\n",
      "Test R2: 0.517640596108804\n",
      "Epoch [110/110], Loss: 545.3775024414062, Train RMSE: 22.881160736083984, Train R^2: 0.9963635472074297\n",
      "Test RMSE: 188.84309489474526\n",
      "Test R2: 0.1311656911546425\n",
      "Epoch [110/110], Loss: 622.5499267578125, Train RMSE: 24.33307647705078, Train R^2: 0.995887405869381\n",
      "Test RMSE: 162.41276551288243\n",
      "Test R2: 0.3573491794970408\n",
      "Epoch [110/110], Loss: 508.53240966796875, Train RMSE: 22.17816162109375, Train R^2: 0.9965835670433084\n",
      "Test RMSE: 184.52398010260762\n",
      "Test R2: 0.17045419654172766\n",
      "Epoch [110/110], Loss: 544.9860229492188, Train RMSE: 22.780986785888672, Train R^2: 0.9963953186938288\n",
      "Test RMSE: 161.13096578287067\n",
      "Test R2: 0.36745305320024946\n",
      "Epoch [110/110], Loss: 514.3029174804688, Train RMSE: 22.1695556640625, Train R^2: 0.9965862179018604\n",
      "Test RMSE: 180.44775390593972\n",
      "Test R2: 0.20669954256075818\n",
      "Epoch [110/110], Loss: 469.69561767578125, Train RMSE: 21.006271362304688, Train R^2: 0.9969350759492608\n",
      "Test RMSE: 176.4105556139567\n",
      "Test R2: 0.24179982718834425\n",
      "Epoch [110/110], Loss: 756.8290405273438, Train RMSE: 27.21957778930664, Train R^2: 0.9948538238627505\n",
      "Test RMSE: 159.55025470790738\n",
      "Test R2: 0.3798028771715296\n",
      "Epoch [110/110], Loss: 531.3571166992188, Train RMSE: 22.50301742553711, Train R^2: 0.9964827493763344\n",
      "Test RMSE: 172.91124190158376\n",
      "Test R2: 0.27158110365798327\n",
      "Epoch [110/110], Loss: 468.57666015625, Train RMSE: 21.01905632019043, Train R^2: 0.9969313435098174\n",
      "Test RMSE: 174.36333329167866\n",
      "Test R2: 0.25929535340746024\n",
      "Epoch [110/110], Loss: 559.66064453125, Train RMSE: 23.57616424560547, Train R^2: 0.996139281808419\n",
      "Test RMSE: 161.63951106505408\n",
      "Test R2: 0.3634539908349679\n",
      "Epoch [110/110], Loss: 582.5175170898438, Train RMSE: 23.807144165039062, Train R^2: 0.9960632633237633\n",
      "Test RMSE: 185.5894650220074\n",
      "Test R2: 0.1608465523145558\n",
      "Epoch [110/110], Loss: 661.4873046875, Train RMSE: 25.38355255126953, Train R^2: 0.9955246540938192\n",
      "Test RMSE: 173.92696569992344\n",
      "Test R2: 0.2629981393854077\n",
      "Epoch [110/110], Loss: 602.6890258789062, Train RMSE: 24.03940200805664, Train R^2: 0.9959860764436814\n",
      "Test RMSE: 162.1083024850859\n",
      "Test R2: 0.3597563796484119\n",
      "Epoch [110/110], Loss: 342.3194580078125, Train RMSE: 17.928571701049805, Train R^2: 0.9977673887263142\n",
      "Test RMSE: 161.1003152689232\n",
      "Test R2: 0.3676936778986504\n",
      "Epoch [110/110], Loss: 541.05322265625, Train RMSE: 22.890972137451172, Train R^2: 0.9963604286756307\n",
      "Test RMSE: 174.09842629809035\n",
      "Test R2: 0.26154432149372464\n",
      "Epoch [110/110], Loss: 622.3427734375, Train RMSE: 24.287778854370117, Train R^2: 0.9959027032389202\n",
      "Test RMSE: 162.86888770242825\n",
      "Test R2: 0.3537344524187317\n",
      "Epoch [110/110], Loss: 444.0251159667969, Train RMSE: 20.311920166015625, Train R^2: 0.9971343454861415\n",
      "Test RMSE: 176.09504562018796\n",
      "Test R2: 0.24450948148216467\n",
      "Epoch [110/110], Loss: 577.0635375976562, Train RMSE: 23.60129165649414, Train R^2: 0.9961310477712648\n",
      "Test RMSE: 161.73569819774514\n",
      "Test R2: 0.3626961841274715\n",
      "Epoch [110/110], Loss: 568.933837890625, Train RMSE: 23.369028091430664, Train R^2: 0.9962068228054393\n",
      "Test RMSE: 167.74882347861947\n",
      "Test R2: 0.3144269938932246\n",
      "Epoch [110/110], Loss: 527.5928955078125, Train RMSE: 22.311580657958984, Train R^2: 0.9965423385569009\n",
      "Test RMSE: 169.0298287664838\n",
      "Test R2: 0.3039163282580457\n",
      "Epoch [110/110], Loss: 217.65164184570312, Train RMSE: 14.173640251159668, Train R^2: 0.9986046453691623\n",
      "Test RMSE: 183.0039122655878\n",
      "Test R2: 0.18406513334303742\n",
      "Epoch [110/110], Loss: 481.5774230957031, Train RMSE: 21.377927780151367, Train R^2: 0.9968256630948495\n",
      "Test RMSE: 178.60943896760304\n",
      "Test R2: 0.22278073655465525\n",
      "Epoch [110/110], Loss: 282.5119934082031, Train RMSE: 16.204174041748047, Train R^2: 0.9981762065733877\n",
      "Test RMSE: 171.52700363211642\n",
      "Test R2: 0.28319711329613784\n",
      "Epoch [110/110], Loss: 548.2333374023438, Train RMSE: 22.864477157592773, Train R^2: 0.9963688488604299\n",
      "Test RMSE: 192.2328677193102\n",
      "Test R2: 0.09969423103425712\n",
      "Epoch [110/110], Loss: 660.3705444335938, Train RMSE: 25.6013240814209, Train R^2: 0.9954475349378243\n",
      "Test RMSE: 177.81641520263506\n",
      "Test R2: 0.22966710324756867\n",
      "Epoch [110/110], Loss: 465.6548767089844, Train RMSE: 21.02152442932129, Train R^2: 0.9969306232316554\n",
      "Test RMSE: 167.99592827968846\n",
      "Test R2: 0.31240572003276046\n",
      "Epoch [110/110], Loss: 707.3779907226562, Train RMSE: 26.310728073120117, Train R^2: 0.9951917447417894\n",
      "Test RMSE: 152.17241130923196\n",
      "Test R2: 0.4358344170510223\n",
      "Epoch [110/110], Loss: 607.6055297851562, Train RMSE: 24.20318031311035, Train R^2: 0.9959311962243017\n",
      "Test RMSE: 166.23493424896367\n",
      "Test R2: 0.32674539069388364\n",
      "Epoch [110/110], Loss: 193.2869110107422, Train RMSE: 13.372050285339355, Train R^2: 0.9987580109887253\n",
      "Test RMSE: 157.53706680691926\n",
      "Test R2: 0.3953552956155004\n",
      "Epoch [110/110], Loss: 527.940673828125, Train RMSE: 22.329225540161133, Train R^2: 0.9965368668348412\n",
      "Test RMSE: 175.53348025411046\n",
      "Test R2: 0.2493203020468988\n",
      "Epoch [110/110], Loss: 569.6337280273438, Train RMSE: 23.425901412963867, Train R^2: 0.99618833798831\n",
      "Test RMSE: 175.04910365758278\n",
      "Test R2: 0.25345751839752684\n",
      "Epoch [110/110], Loss: 525.6171875, Train RMSE: 22.311853408813477, Train R^2: 0.9965422540375634\n",
      "Test RMSE: 175.94872958184197\n",
      "Test R2: 0.2457644225931609\n",
      "Best Test R2: 0.517640596108804\n",
      "Best i: 63\n",
      "Best j: 32\n"
     ]
    }
   ],
   "source": [
    "best_r2 = -1  \n",
    "best_i = -1 \n",
    "best_j = -1  \n",
    "for i in range(60,70):\n",
    "    for j in range (30,35):\n",
    "        model = one_dim_CNN_Initialization(1,i,3,j)\n",
    "        batch_size, learning_rate, num_epochs = Super_Parameters(batch_size=57,learning_rate=0.001,num_epochs=110)\n",
    "        # Train\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        total_step = len(train_dataloader)\n",
    "        for epoch in range(num_epochs):\n",
    "            for inputs, targets in train_dataloader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)  \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_outputs = model(data_train_tensor)\n",
    "                train_rmse = mean_squared_error(labels_train_tensor, train_outputs.detach().numpy(), squared=False)\n",
    "                train_r2 = r2_score(labels_train_tensor, train_outputs.detach().numpy())\n",
    "\n",
    "        # print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, Train RMSE: {train_rmse}, Train R^2: {train_r2}\")\n",
    "\n",
    "        model_path = \"1dcnnmodel.pth\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        cnnmodel_test = Custom1DCNN(1,i,3,j)\n",
    "        cnnmodel_test.load_state_dict(torch.load(model_path))\n",
    "\n",
    "        test_outputs = cnnmodel_test(data_test_tensor)\n",
    "        test_outputs = test_outputs.detach().numpy()\n",
    "\n",
    "        test_rmse = mean_squared_error(labels_test, test_outputs, squared=False)\n",
    "        test_r2 = r2_score(labels_test, test_outputs)\n",
    "        print(\"Test RMSE:\", test_rmse)\n",
    "        print(\"Test R2:\",test_r2)\n",
    "        if test_r2 > best_r2:  # 如果当前模型的测试 R2 值更好\n",
    "            best_r2 = test_r2\n",
    "            best_i = i\n",
    "            best_j = j\n",
    "        if test_r2 > 0.55:\n",
    "            print(\"output channels:\",i)\n",
    "            print(\"hidden_size:\",j)\n",
    "            break\n",
    "\n",
    "print(\"Best Test R2:\", best_r2)\n",
    "print(\"Best i:\", best_i)\n",
    "print(\"Best j:\", best_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Test R2: 0.517640596108804\n",
    "Best i: 63\n",
    "Best j: 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom_1d_cnn_graph.png'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "\n",
    "# 随机生成输入数据作为示例\n",
    "batch_size = 1\n",
    "sequence_length = 2048\n",
    "input_data = torch.randn(batch_size, in_channels, sequence_length)\n",
    "\n",
    "# 获取模型输出\n",
    "output = model(input_data)\n",
    "\n",
    "# 使用torchviz可视化模型\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.render(\"custom_1d_cnn_graph\", format=\"png\")  # 将图保存为PNG格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((2048 * (1/3)**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
